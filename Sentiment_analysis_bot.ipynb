{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KushagraGoel2024/Quote-analysis-author-and-sentiment/blob/main/Sentiment_analysis_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALm5hjVqhmQb",
        "outputId": "4b4f85a4-477b-4ec2-a34e-9c61b0549360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.14)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Building wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp310-cp310-linux_x86_64.whl size=255323 sha256=ad32dbe80090544d19a23038e4cf955adb253355895b1124113ab407af96a527\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/14/ef/4aab19d27fa8e58772be5c71c16add0426acf9e1f64353235c\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorflow scikit-learn pandas numpy pickle5\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, LSTM, Bidirectional, SimpleRNN\n",
        "import pickle5 as pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8x3T7Jj7F3v",
        "outputId": "d3b043e2-79bf-4012-cab3-8f95c738e255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Glulbgjc7PPy",
        "outputId": "f859e32c-cde9-4558-8080-ca3caa181180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  quote           tags\n",
            "0        “Be yourself; everyone else is already taken.”  inspirational\n",
            "1     “I'm selfish, impatient and a little insecure....   deep meaning\n",
            "2     “Two things are infinite: the universe and hum...          humor\n",
            "3                      “So many books, so little time.”   deep meaning\n",
            "4     “A room without books is like a body without a...   deep meaning\n",
            "...                                                 ...            ...\n",
            "2500  “Morality is simply the attitude we adopt towa...          humor\n",
            "2501  “Don't aim at success. The more you aim at it ...   deep meaning\n",
            "2502  “In life, finding a voice is speaking and livi...  inspirational\n",
            "2503  “Winter is the time for comfort, for good food...          humor\n",
            "2504                      “Silence is so freaking loud”          humor\n",
            "\n",
            "[2505 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/gdrive/My Drive/quotes.csv')\n",
        "df = df[['quote', 'tags']]\n",
        "df1=df\n",
        "print(df1)\n",
        "df1 = df1.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jVL7oud-RwB",
        "outputId": "3358d2c8-f32f-4386-f5e1-fab7822a10a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      deep meaning  humor  inspirational  love\n",
            "0                1      0              0     0\n",
            "1                1      0              0     0\n",
            "2                0      0              1     0\n",
            "3                0      0              1     0\n",
            "4                0      0              1     0\n",
            "...            ...    ...            ...   ...\n",
            "2500             0      0              1     0\n",
            "2501             0      1              0     0\n",
            "2502             0      0              1     0\n",
            "2503             0      0              0     1\n",
            "2504             0      0              1     0\n",
            "\n",
            "[2505 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(df1['quote'])\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(df1['quote'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=500, truncating='post')\n",
        "tagslabels = pd.get_dummies(df1['tags']).values\n",
        "print(pd.get_dummies(df1['tags']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sz1uepq3_ais"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(padded_sequences, tagslabels, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf0R9VxKHLw2",
        "outputId": "fcbdea33-edf1-4cb8-dad2-6aefc0dd60b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 100)          500000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 500, 200)          60200     \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 500, 200)          80200     \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 400)              641600    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 1604      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,283,604\n",
            "Trainable params: 1,283,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(5000, 100, input_length=500))\n",
        "model.add(SimpleRNN(200,return_sequences=True))\n",
        "model.add(SimpleRNN(200,return_sequences=True))\n",
        "model.add(Bidirectional(LSTM(200)))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icl4x5JEAl14",
        "outputId": "9415e087-e5df-4d4a-cf42-b396da2d6b4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "55/55 [==============================] - 282s 5s/step - loss: 1.1591 - accuracy: 0.5003 - val_loss: 1.1815 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "55/55 [==============================] - 268s 5s/step - loss: 1.1247 - accuracy: 0.5231 - val_loss: 1.1892 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "55/55 [==============================] - 266s 5s/step - loss: 1.1261 - accuracy: 0.5231 - val_loss: 1.1807 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "55/55 [==============================] - 274s 5s/step - loss: 1.1306 - accuracy: 0.5106 - val_loss: 1.1771 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "55/55 [==============================] - 270s 5s/step - loss: 1.1128 - accuracy: 0.5237 - val_loss: 1.1755 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "55/55 [==============================] - 271s 5s/step - loss: 1.1163 - accuracy: 0.5237 - val_loss: 1.1927 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "55/55 [==============================] - 273s 5s/step - loss: 1.1111 - accuracy: 0.5237 - val_loss: 1.1804 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "55/55 [==============================] - 259s 5s/step - loss: 1.1100 - accuracy: 0.5237 - val_loss: 1.1797 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "55/55 [==============================] - 258s 5s/step - loss: 1.1128 - accuracy: 0.5237 - val_loss: 1.1815 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "55/55 [==============================] - 262s 5s/step - loss: 1.1108 - accuracy: 0.5237 - val_loss: 1.1900 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "55/55 [==============================] - 264s 5s/step - loss: 1.1098 - accuracy: 0.5237 - val_loss: 1.1863 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "55/55 [==============================] - 259s 5s/step - loss: 1.1102 - accuracy: 0.5231 - val_loss: 1.1883 - val_accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "55/55 [==============================] - 259s 5s/step - loss: 1.1101 - accuracy: 0.5231 - val_loss: 1.1819 - val_accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "55/55 [==============================] - 259s 5s/step - loss: 1.1101 - accuracy: 0.5231 - val_loss: 1.1833 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "55/55 [==============================] - 259s 5s/step - loss: 1.1101 - accuracy: 0.5231 - val_loss: 1.1833 - val_accuracy: 0.5000\n",
            "Epoch 16/50\n",
            "55/55 [==============================] - 259s 5s/step - loss: 1.1106 - accuracy: 0.5237 - val_loss: 1.1786 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "55/55 [==============================] - 262s 5s/step - loss: 1.1100 - accuracy: 0.5237 - val_loss: 1.1839 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "55/55 [==============================] - 261s 5s/step - loss: 1.1098 - accuracy: 0.5237 - val_loss: 1.1811 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "55/55 [==============================] - 262s 5s/step - loss: 1.1093 - accuracy: 0.5237 - val_loss: 1.1754 - val_accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "55/55 [==============================] - 257s 5s/step - loss: 1.1095 - accuracy: 0.5237 - val_loss: 1.1814 - val_accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "55/55 [==============================] - 274s 5s/step - loss: 1.1087 - accuracy: 0.5237 - val_loss: 1.1886 - val_accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "55/55 [==============================] - 263s 5s/step - loss: 1.1086 - accuracy: 0.5242 - val_loss: 1.1820 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "55/55 [==============================] - 279s 5s/step - loss: 1.1082 - accuracy: 0.5242 - val_loss: 1.1815 - val_accuracy: 0.5000\n",
            "Epoch 24/50\n",
            "55/55 [==============================] - 278s 5s/step - loss: 1.1096 - accuracy: 0.5242 - val_loss: 1.1807 - val_accuracy: 0.5000\n",
            "Epoch 25/50\n",
            "55/55 [==============================] - 279s 5s/step - loss: 1.1080 - accuracy: 0.5242 - val_loss: 1.1859 - val_accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "55/55 [==============================] - 274s 5s/step - loss: 1.1086 - accuracy: 0.5242 - val_loss: 1.1775 - val_accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "55/55 [==============================] - 260s 5s/step - loss: 1.1059 - accuracy: 0.5242 - val_loss: 1.1849 - val_accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "55/55 [==============================] - 256s 5s/step - loss: 1.0943 - accuracy: 0.5385 - val_loss: 1.1739 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "55/55 [==============================] - 258s 5s/step - loss: 0.9457 - accuracy: 0.6104 - val_loss: 1.3154 - val_accuracy: 0.4348\n",
            "Epoch 30/50\n",
            "55/55 [==============================] - 259s 5s/step - loss: 0.7008 - accuracy: 0.7273 - val_loss: 1.6045 - val_accuracy: 0.4574\n",
            "Epoch 31/50\n",
            "55/55 [==============================] - 258s 5s/step - loss: 0.5261 - accuracy: 0.7804 - val_loss: 1.7853 - val_accuracy: 0.4043\n",
            "Epoch 32/50\n",
            "55/55 [==============================] - 259s 5s/step - loss: 0.5245 - accuracy: 0.7941 - val_loss: 1.3164 - val_accuracy: 0.4269\n",
            "Epoch 33/50\n",
            "55/55 [==============================] - 242s 4s/step - loss: 0.5413 - accuracy: 0.7912 - val_loss: 2.1716 - val_accuracy: 0.3963\n",
            "Epoch 34/50\n",
            "55/55 [==============================] - 242s 4s/step - loss: 0.5032 - accuracy: 0.7963 - val_loss: 1.9806 - val_accuracy: 0.3777\n",
            "Epoch 35/50\n",
            "55/55 [==============================] - 261s 5s/step - loss: 0.4388 - accuracy: 0.8300 - val_loss: 2.3914 - val_accuracy: 0.3790\n",
            "Epoch 36/50\n",
            "55/55 [==============================] - 260s 5s/step - loss: 1.1274 - accuracy: 0.5722 - val_loss: 1.1839 - val_accuracy: 0.5000\n",
            "Epoch 37/50\n",
            "55/55 [==============================] - 258s 5s/step - loss: 1.1287 - accuracy: 0.5060 - val_loss: 1.1803 - val_accuracy: 0.5000\n",
            "Epoch 38/50\n",
            "55/55 [==============================] - 260s 5s/step - loss: 1.0925 - accuracy: 0.5271 - val_loss: 1.2060 - val_accuracy: 0.5000\n",
            "Epoch 39/50\n",
            "55/55 [==============================] - 258s 5s/step - loss: 0.8149 - accuracy: 0.6863 - val_loss: 1.4058 - val_accuracy: 0.4894\n",
            "Epoch 40/50\n",
            "55/55 [==============================] - 261s 5s/step - loss: 0.5128 - accuracy: 0.7969 - val_loss: 1.8470 - val_accuracy: 0.4003\n",
            "Epoch 41/50\n",
            "55/55 [==============================] - 260s 5s/step - loss: 0.3714 - accuracy: 0.8574 - val_loss: 2.2265 - val_accuracy: 0.3790\n",
            "Epoch 42/50\n",
            "55/55 [==============================] - 260s 5s/step - loss: 0.2957 - accuracy: 0.8922 - val_loss: 2.3534 - val_accuracy: 0.3843\n",
            "Epoch 43/50\n",
            "55/55 [==============================] - 259s 5s/step - loss: 0.2657 - accuracy: 0.8990 - val_loss: 2.4073 - val_accuracy: 0.4109\n",
            "Epoch 44/50\n",
            "55/55 [==============================] - 257s 5s/step - loss: 0.2145 - accuracy: 0.9224 - val_loss: 2.8039 - val_accuracy: 0.4122\n",
            "Epoch 45/50\n",
            "55/55 [==============================] - 256s 5s/step - loss: 0.1652 - accuracy: 0.9384 - val_loss: 2.5491 - val_accuracy: 0.4441\n",
            "Epoch 46/50\n",
            "55/55 [==============================] - 255s 5s/step - loss: 0.1409 - accuracy: 0.9515 - val_loss: 2.8745 - val_accuracy: 0.3896\n",
            "Epoch 47/50\n",
            "55/55 [==============================] - 256s 5s/step - loss: 0.0930 - accuracy: 0.9681 - val_loss: 3.1079 - val_accuracy: 0.3497\n",
            "Epoch 48/50\n",
            "55/55 [==============================] - 254s 5s/step - loss: 0.1227 - accuracy: 0.9612 - val_loss: 2.9817 - val_accuracy: 0.4043\n",
            "Epoch 49/50\n",
            "55/55 [==============================] - 256s 5s/step - loss: 0.0804 - accuracy: 0.9772 - val_loss: 2.6839 - val_accuracy: 0.4428\n",
            "Epoch 50/50\n",
            "55/55 [==============================] - 259s 5s/step - loss: 0.0728 - accuracy: 0.9760 - val_loss: 3.2081 - val_accuracy: 0.4215\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x79f9104ff910>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=50 , batch_size=32, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhZdtV7Qnmw4"
      },
      "outputs": [],
      "source": [
        "model.save('/content/gdrive/MyDrive/sentiment_analysis_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwmFSeBfwFeM"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "model = keras.models.load_model('/content/gdrive/MyDrive/sentiment_analysis_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_ww6JRMwJVX"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(text):\n",
        "    text_sequence = tokenizer.texts_to_sequences([text])\n",
        "    text_sequence = pad_sequences(text_sequence, maxlen=500)\n",
        "    return model.predict(text_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nAlKH5BtwV9M",
        "outputId": "fd2dd954-2703-44ad-a916-6354be3c44b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 181ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 179ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 239ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 320ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 354ms/step\n",
            "humor\n",
            "1/1 [==============================] - 1s 543ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 1s 584ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 1s 764ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 1s 614ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 449ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 421ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 437ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 335ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 339ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 342ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 410ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 370ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 399ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 370ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 372ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 404ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 460ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 366ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 366ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 329ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 369ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 399ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 389ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 1s 550ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 327ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 298ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 312ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 409ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 365ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 392ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 343ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 330ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 322ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 232ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 197ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 192ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 186ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 197ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 202ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 193ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 185ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 201ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 191ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 189ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 196ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 191ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 179ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 202ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 201ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 195ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 194ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 198ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 198ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 195ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 179ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 206ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 196ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 205ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 189ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 190ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 206ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 202ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 185ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 239ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 312ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 330ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 319ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 322ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 342ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 330ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 364ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 377ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 368ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 202ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 185ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 210ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 214ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 205ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 192ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 185ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 192ms/step\n",
            "love\n",
            "1/1 [==============================] - 0s 202ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 186ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 179ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 192ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 206ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 191ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 189ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 192ms/step\n",
            "love\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "love\n",
            "1/1 [==============================] - 0s 198ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 195ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 190ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 200ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "love\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 204ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 227ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 191ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 206ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 179ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 299ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 327ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 314ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 326ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 391ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 375ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 313ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 310ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 317ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 315ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 196ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 179ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 198ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 178ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 180ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 192ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 180ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 208ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 185ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 180ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 205ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 179ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 191ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 197ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 197ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 191ms/step\n",
            "love\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 207ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 198ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 210ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 320ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 306ms/step\n",
            "love\n",
            "1/1 [==============================] - 0s 298ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 311ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 338ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 336ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 332ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 346ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 345ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 199ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 203ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 200ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 205ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 186ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 200ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 194ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 186ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 196ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 208ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 190ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 201ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 186ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 193ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "love\n",
            "1/1 [==============================] - 0s 180ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 190ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 202ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 190ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 210ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 196ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 199ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 197ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 191ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 189ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 179ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 198ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 316ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 309ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 334ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 315ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 309ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 342ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 1s 657ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 348ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 347ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 336ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 191ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 216ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 191ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 180ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 194ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 192ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 180ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 216ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 201ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 193ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 179ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 186ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 203ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 199ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 198ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 194ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 228ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 193ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 180ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 203ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 219ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 196ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 193ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 201ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 207ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 198ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 337ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 1s 605ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 318ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 333ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 335ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 322ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 332ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 308ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 356ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 332ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 310ms/step\n",
            "deep meaning\n",
            "1/1 [==============================] - 0s 195ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 189ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 191ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 200ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 195ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 189ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 194ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 201ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 196ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 194ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 329ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 194ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 386ms/step\n",
            "humor\n",
            "1/1 [==============================] - 0s 201ms/step\n",
            "inspirational\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "inspirational\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-547227c85b9b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2505\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mtext_input\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quote'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mpredicted_entiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredicted_entiment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-2f767c022e4b>\u001b[0m in \u001b[0;36mpredict_sentiment\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtext_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtext_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2380\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2382\u001b[0;31m                         \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2383\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m                             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for n in range(200,2505):\n",
        "  text_input =(df.iloc[n]['quote'])\n",
        "  predicted_entiment = predict_sentiment(text_input)\n",
        "  for i in predicted_entiment:\n",
        "    d=max(i)\n",
        "    for n in range(0,4):\n",
        "      if i[n]==d:\n",
        "        if n==0:\n",
        "          print('deep meaning')\n",
        "        if n==1:\n",
        "          print('humor')\n",
        "        if n==2:\n",
        "          print('inspirational')\n",
        "        if n==3:\n",
        "          print('love')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}